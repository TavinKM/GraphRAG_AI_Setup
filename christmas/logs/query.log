2025-10-16 17:53:23.0159 - WARNING - graphrag.query.structured_search.global_search.search - Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.
2025-10-16 17:55:10.0221 - WARNING - graphrag.query.structured_search.global_search.search - Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.
2025-10-16 17:59:19.0134 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 17:59:22.0150 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 17:59:26.0578 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 17:59:34.0593 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 17:59:51.0378 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:00:23.0620 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:15:48.0717 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:15:51.0732 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:15:56.0156 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:16:04.0177 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:16:20.0975 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:16:53.0215 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:17:57.0595 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:20:06.0394 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:26:58.0756 - WARNING - graphrag.query.structured_search.global_search.search - Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.
2025-10-16 18:28:02.0286 - WARNING - graphrag.query.structured_search.global_search.search - Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.
2025-10-16 18:31:04.0849 - WARNING - graphrag.query.structured_search.global_search.search - Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.
2025-10-16 18:32:22.0322 - WARNING - graphrag.query.structured_search.global_search.search - Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.
2025-10-16 18:32:55.0415 - WARNING - graphrag.query.structured_search.global_search.search - Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.
2025-10-16 18:40:55.0885 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:40:58.0912 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:41:03.0339 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:41:11.0355 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:41:28.0153 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:42:00.0382 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:43:04.0774 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:45:13.0592 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:49:45.0439 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:49:48.0516 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:49:53.0026 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:50:03.0163 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:50:22.0088 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:50:56.0419 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:53:05.0334 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:53:08.0401 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:53:12.0915 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:53:23.0028 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:53:41.0944 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:54:16.0305 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:55:22.0785 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:56:43.0712 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:56:46.0800 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:56:51.0298 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:57:01.0431 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:57:20.0346 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:57:54.0718 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:59:01.0224 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/chat/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:59:42.0079 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:59:45.0165 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:59:49.0668 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 18:59:59.0795 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 19:00:18.0669 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 19:00:53.0003 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 19:01:59.0468 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/completions/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 19:03:58.0184 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 19:04:01.0240 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 19:04:05.0757 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 19:04:15.0893 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 19:04:34.0784 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
2025-10-16 19:05:09.0144 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - 404 page not found
Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 124, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 337, in post
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 293, in post
    response.raise_for_status()
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'http://localhost:11434/v1/api/generate'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 256, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 149, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3312, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: 404 page not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1628, in wrapper_async
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\utils.py", line 1474, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\mistr\anaconda3\envs\graphRAG\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - 404 page not found
